{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_pairs(df):\n",
    "    count = 0\n",
    "    for row in df.iterrows():\n",
    "        for col in df:\n",
    "            if not (col == \"original\") and not (row[1][col] == \"\") and not (type(row[1][col]) == float):\n",
    "                count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split_sizes(directory):\n",
    "    data = defaultdict(lambda:{\"train\": 0, \"test\": 0, \"val\": 0})\n",
    "    for dir_name in os.listdir(directory):\n",
    "        dir = os.path.join(directory, dir_name)\n",
    "        if os.path.isdir(dir):\n",
    "            for file_name in os.listdir(dir):\n",
    "                file = os.path.join(dir, file_name)\n",
    "                if os.path.isfile(file) and file_name[-4:] == \".csv\":\n",
    "                    name_split = file_name.split(\"_\")\n",
    "                    dataset_name = name_split[0]\n",
    "                    split = name_split[1].split(\".\")[0]\n",
    "                    data[dataset_name][split] = get_total_pairs(pd.read_csv(file))\n",
    "    output = defaultdict(lambda:[])\n",
    "    for dataset in data:\n",
    "        output['name'].append(dataset)\n",
    "        output['train'].append(data[dataset]['train'])\n",
    "        output['test'].append(data[dataset]['test'])\n",
    "        output['val'].append(data[dataset]['val'])\n",
    "    \n",
    "    return pd.DataFrame(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_split_sizes(\"../data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                name   train  test   val\n",
      "0             Easy Japanese Extended   32248   731  1000\n",
      "1               Easy Japanese Corpus   27600  1000  1000\n",
      "2   TextComplexityDE Parallel Corpus     144    25    25\n",
      "3                     GEOLino Corpus     437   122   118\n",
      "4                        German News    1748  1024  1023\n",
      "5        Text Simplification Slovene     188    96    94\n",
      "6                         PorSimples    1949   790   784\n",
      "7                         SimplifyUR     470    51    74\n",
      "8                        RuWikiLarge  135191   365   768\n",
      "9                        RSSE Corpus    1477  3398   341\n",
      "10                      RuAdapt Ency    1450   982   965\n",
      "11                RuAdapt Fairytales      97    31    31\n",
      "12                RuAdapt Literature   10515  1000  1000\n",
      "13                           Teacher      83    17    17\n",
      "14                           AdminIT     114    73    75\n",
      "15                           Terence     394   101   102\n",
      "16       Simpitiki Italian Wikipedia      24    56    59\n",
      "17                  PaCCSS-IT Corpus   55274  1267  1254\n",
      "18                          WikiAuto  315018  5012  5012\n",
      "19                             ASSET   14814  3590  1000\n",
      "20                        Newsela EN  129387   991  1008\n",
      "21                       DSim Corpus   25524   997  1005\n",
      "22                      CLEAR Corpus    3179   100   300\n",
      "23                WikiLargeFR Corpus  148276   359   992\n",
      "24                        Newsela ES   17022  1001  1001\n",
      "25                          Simplext     157    92    93\n",
      "26                              CBST     218    46    46\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1094070"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5002"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_total_pairs(pd.read_csv(\"../data/Japanese/Easy Japanese Corpus_test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../output/misc/data_size_split.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

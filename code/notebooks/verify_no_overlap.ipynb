{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def verify_no_overlap(df1, df2):\n",
    "    inner = pd.merge(df1, df2, how ='inner', on =['original', 'original'])\n",
    "    return len(inner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_overlap_all_data(directory):\n",
    "    for dir_name in os.listdir(directory):\n",
    "        dir = os.path.join(directory, dir_name)\n",
    "        if os.path.isdir(dir):\n",
    "            print(\"--------------\" + dir_name + \"--------------\")\n",
    "            other_files = [os.path.join(dir,file) for file in os.listdir(dir) if (file[-4:] == \".csv\" and os.path.isfile(os.path.join(dir,file)))]\n",
    "            while len(other_files) > 1:\n",
    "                test_file = other_files.pop(0)\n",
    "                df1 = pd.read_csv(test_file)\n",
    "                for data_file in other_files:\n",
    "                    print (\"TESTING \" + test_file + \" vs \" + data_file + \": \", end=\"\")\n",
    "                    df2 = pd.read_csv(data_file)\n",
    "                    overlap = verify_no_overlap(df1,df2)\n",
    "                    if (overlap == 0):\n",
    "                        print(\"OKAY\")\n",
    "                    else:\n",
    "                        print(\"BAD (\" + str(overlap) + \" overlap original sentences) [MUST FIX!!!]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_swap(from_counts, from_df, disallow):\n",
    "    random_line = from_df.sample()\n",
    "    while (random_line.iloc[0]['original'] not in from_counts) \\\n",
    "      or (from_counts[random_line.iloc[0]['original']] != 1) \\\n",
    "      or (random_line.iloc[0]['original'] == disallow):\n",
    "        random_line = from_df.sample()\n",
    "    return random_line\n",
    "\n",
    "def fix_overlap(path1, path2):\n",
    "    df1 = pd.read_csv(path1)\n",
    "    df2 = pd.read_csv(path2)\n",
    "    df1_counts = df1['original'].value_counts()\n",
    "    df2_counts = df2['original'].value_counts()\n",
    "    inner = pd.merge(df1, df2, how ='inner', on =['original', 'original'])\n",
    "    original_len_df1 = df1.shape[0]\n",
    "    original_len_df2 = df2.shape[0]\n",
    "    for sentence in tqdm(inner['original']):\n",
    "        if sentence in df1_counts and sentence in df2_counts:\n",
    "            if df1_counts[sentence] > df2_counts[sentence]:\n",
    "                row = df2.loc[df2['original'] == sentence].iloc[:1]\n",
    "                if not row.empty:\n",
    "                    # Move overlap line to df1\n",
    "                    df1 = pd.concat([df1, row], ignore_index=True)\n",
    "                    df2 = df2.drop(row.index)\n",
    "\n",
    "                    # Move random line to df2\n",
    "                    random_line = select_swap(df1_counts, df1, sentence)\n",
    "                    df2 = pd.concat([df2, random_line], ignore_index=True)\n",
    "                    df1 = df1.drop(random_line.index)\n",
    "                \n",
    "            else:\n",
    "                row = df1.loc[df1['original'] == sentence].iloc[:1]\n",
    "                if not row.empty:\n",
    "                    # Move overlap line to df2\n",
    "                    df2 = pd.concat([df2, row], ignore_index=True)\n",
    "                    df1 = df1.drop(row.index)\n",
    "\n",
    "                    # Move random line to df1\n",
    "                    random_line = select_swap(df2_counts, df2, sentence)\n",
    "                    df1 = pd.concat([df1, random_line], ignore_index=True)\n",
    "                    df2 = df2.drop(random_line.index)\n",
    "            df1_counts = df1['original'].value_counts()\n",
    "            df2_counts = df2['original'].value_counts()\n",
    "\n",
    "    assert df1.shape[0] == original_len_df1\n",
    "    assert df2.shape[0] == original_len_df2\n",
    "\n",
    "    df1.to_csv(path1, index=False)\n",
    "    df2.to_csv(path2, index=False)\n",
    "\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_overlap_no_replace(path1_from, path2_to):\n",
    "    df1 = pd.read_csv(path1_from)\n",
    "    df2 = pd.read_csv(path2_to)\n",
    "    df1_counts = df1['original'].value_counts()\n",
    "    df2_counts = df2['original'].value_counts()\n",
    "    inner = pd.merge(df1, df2, how ='inner', on =['original', 'original'])\n",
    "    move_size = 0\n",
    "    original_len_df1 = df1.shape[0]\n",
    "    original_len_df2 = df2.shape[0]\n",
    "    for sentence in tqdm(inner['original']):\n",
    "        if sentence in df1_counts and sentence in df2_counts:\n",
    "            row = df1.loc[df1['original'] == sentence].iloc[:1]\n",
    "            if not row.empty:\n",
    "                move_size += 1\n",
    "                # Move overlap line to df2\n",
    "                df2 = pd.concat([df2, row], ignore_index=True)\n",
    "                df1 = df1.drop(row.index)\n",
    "\n",
    "            df1_counts = df1['original'].value_counts()\n",
    "            df2_counts = df2['original'].value_counts()\n",
    "\n",
    "    assert df1.shape[0] + move_size == original_len_df1\n",
    "    assert df2.shape[0] - move_size == original_len_df2\n",
    "\n",
    "    df1.to_csv(path1_from, index=False)\n",
    "    df2.to_csv(path2_to, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 44.77it/s]\n"
     ]
    }
   ],
   "source": [
    "fix_overlap(\"../data/Japanese/Easy Japanese Corpus_train.csv\", \"../data/Japanese/Easy Japanese Corpus_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap_row(df_from, df_to, df_to_counts, sentence):\n",
    "    row = df_from.loc[df_from['original'] == sentence].iloc[:1]\n",
    "    if not row.empty:\n",
    "        # Move overlap line to df1\n",
    "        df_to = pd.concat([df_to, row], ignore_index=True)\n",
    "        df_from = df_from.drop(row.index)\n",
    "\n",
    "        # Move random line to df2\n",
    "        random_line = select_swap(df_to_counts, df_to, sentence)\n",
    "        df_from = pd.concat([df_from, random_line], ignore_index=True)\n",
    "        df_to = df_to.drop(random_line.index)\n",
    "    return df_from, df_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_splits(train1_path, test1_path, train2_path, test2_path):\n",
    "    tr1, te1, tr2, te2 = [pd.read_csv(path) for path in [train1_path, test1_path, train2_path, test2_path]]\n",
    "    tr1_counts, te1_counts, tr2_counts, te2_counts = [df['original'].value_counts() for df in [tr1, te1, tr2, te2]]\n",
    "    tr1_olen, te1_olen, tr2_olen, te2_olen = [df.shape[0] for df in [tr1,te1,tr2,te2]]\n",
    "\n",
    "    assert verify_no_overlap(tr1, te1) == 0, \"train/test dataframe 1 do not have zero overlap to begin.  Please use fix_overlap.\"\n",
    "    assert verify_no_overlap(tr2, te2) == 0, \"train/test dataframe 2 do not have zero overlap to begin.  Please use fix_overlap.\"\n",
    "\n",
    "    # First guarantee no overlap in train1 and test2\n",
    "    print(\"Align TRAIN1 to TEST2 (reduce overlap)\")\n",
    "    inner = pd.merge(tr1, te2, how ='inner', on =['original', 'original'])\n",
    "    for sentence in tqdm(inner['original']):\n",
    "        if sentence in tr1_counts and sentence in te2_counts:\n",
    "            if tr1_counts[sentence] > te2_counts[sentence]:\n",
    "                te2, tr2 = swap_row(te2, tr2, tr2_counts, sentence)\n",
    "            else:\n",
    "                tr1, te1= swap_row(tr1, te1, te1_counts, sentence)\n",
    "            tr1_counts, te1_counts, tr2_counts, te2_counts = [df['original'].value_counts() for df in [tr1, te1, tr2, te2]]\n",
    "\n",
    "    # Second guarantee no overlap in test1 and train2\n",
    "    print(\"Align TEST1 to TRAIN2 (reduce overlap)\")\n",
    "    inner = pd.merge(te1, tr2, how ='inner', on =['original', 'original'])\n",
    "    for sentence in tqdm(inner['original']):\n",
    "        if sentence in te1_counts and sentence in tr2_counts:\n",
    "            if te1_counts[sentence] >= tr2_counts[sentence]:\n",
    "                tr2, te2 = swap_row(tr2, te2, te2_counts, sentence)\n",
    "            else:\n",
    "                te1, tr1= swap_row(te1, tr1, tr1_counts, sentence)\n",
    "            tr1_counts, te1_counts, tr2_counts, te2_counts = [df['original'].value_counts() for df in [tr1, te1, tr2, te2]]\n",
    "    \n",
    "    assert tr1_olen == tr1.shape[0], \"ERROR: Number of rows in train1 changed\"\n",
    "    assert te1_olen == te1.shape[0], \"ERROR: Number of rows in test1 changed\"\n",
    "    assert tr2_olen == tr2.shape[0], \"ERROR: Number of rows in train2 changed\"\n",
    "    assert te2_olen == te2.shape[0], \"ERROR: Number of rows in test2 changed\"\n",
    "\n",
    "    overlap = verify_no_overlap(tr1, te1)\n",
    "    if overlap > 0:\n",
    "        print(\"TRAIN1 to TEST1: BAD (\" + str(overlap) + \" overlap) rerun fix_overlap\")\n",
    "    overlap = verify_no_overlap(tr2, te2)\n",
    "    if overlap > 0:\n",
    "        print(\"TRAIN2 to TEST2: BAD (\" + str(overlap) + \" overlap) rerun fix_overlap\")\n",
    "    overlap = verify_no_overlap(tr1, te2)\n",
    "    if overlap > 0:\n",
    "        print(\"TRAIN1 to TEST2: BAD (\" + str(overlap) + \" overlap) rerun align_splits\")\n",
    "    overlap = verify_no_overlap(tr2, te1)\n",
    "    if overlap > 0:\n",
    "        print(\"TRAIN2 to TEST1: BAD (\" + str(overlap) + \" overlap) rerun align_splits\")\n",
    "    \n",
    "    tr1.to_csv(train1_path, index=False)\n",
    "    te1.to_csv(test1_path, index=False)\n",
    "    tr2.to_csv(train2_path, index=False)\n",
    "    te2.to_csv(test2_path, index=False)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align the splits without ever modifying train2 or test2\n",
    "def align_splits_oneside(train1_path, test1_path, train2_path_lock, test2_path_lock):\n",
    "    tr1, te1, tr2, te2 = [pd.read_csv(path) for path in [train1_path, test1_path, train2_path_lock, test2_path_lock]]\n",
    "    tr1_counts, te1_counts, tr2_counts, te2_counts = [df['original'].value_counts() for df in [tr1, te1, tr2, te2]]\n",
    "    tr1_olen, te1_olen, tr2_olen, te2_olen = [df.shape[0] for df in [tr1,te1,tr2,te2]]\n",
    "\n",
    "    assert verify_no_overlap(tr1, te1) == 0, \"train/test dataframe 1 do not have zero overlap to begin.  Please use fix_overlap.\"\n",
    "    assert verify_no_overlap(tr2, te2) == 0, \"train/test dataframe 2 do not have zero overlap to begin.  Please use fix_overlap.\"\n",
    "\n",
    "    # First guarantee no overlap in train1 and test2\n",
    "    print(\"Align TRAIN1 to TEST2 (reduce overlap)\")\n",
    "    inner = pd.merge(tr1, te2, how ='inner', on =['original', 'original'])\n",
    "    for sentence in tqdm(inner['original']):\n",
    "        if sentence in tr1_counts:\n",
    "            tr1, te1 = swap_row(tr1, te1, te1_counts, sentence)\n",
    "            tr1_counts, te1_counts = [df['original'].value_counts() for df in [tr1, te1]]\n",
    "\n",
    "    # Second guarantee no overlap in test1 and train2\n",
    "    print(\"Align TEST1 to TRAIN2 (reduce overlap)\")\n",
    "    inner = pd.merge(te1, tr2, how ='inner', on =['original', 'original'])\n",
    "    for sentence in tqdm(inner['original']):\n",
    "        if sentence in te1_counts:\n",
    "            te1, tr1= swap_row(te1, tr1, tr1_counts, sentence)\n",
    "            tr1_counts, te1_counts = [df['original'].value_counts() for df in [tr1, te1]]\n",
    "    \n",
    "    assert tr1_olen == tr1.shape[0], \"ERROR: Number of rows in train1 changed\"\n",
    "    assert te1_olen == te1.shape[0], \"ERROR: Number of rows in test1 changed\"\n",
    "    assert tr2_olen == tr2.shape[0], \"ERROR: Number of rows in train2 changed\"\n",
    "    assert te2_olen == te2.shape[0], \"ERROR: Number of rows in test2 changed\"\n",
    "\n",
    "    overlap = verify_no_overlap(tr1, te1)\n",
    "    if overlap > 0:\n",
    "        print(\"TRAIN1 to TEST1: BAD (\" + str(overlap) + \" overlap) rerun fix_overlap\")\n",
    "    overlap = verify_no_overlap(tr2, te2)\n",
    "    if overlap > 0:\n",
    "        print(\"TRAIN2 to TEST2: BAD (\" + str(overlap) + \" overlap) rerun fix_overlap\")\n",
    "    overlap = verify_no_overlap(tr1, te2)\n",
    "    if overlap > 0:\n",
    "        print(\"TRAIN1 to TEST2: BAD (\" + str(overlap) + \" overlap) rerun align_splits\")\n",
    "    overlap = verify_no_overlap(tr2, te1)\n",
    "    if overlap > 0:\n",
    "        print(\"TRAIN2 to TEST1: BAD (\" + str(overlap) + \" overlap) rerun align_splits\")\n",
    "    \n",
    "    tr1.to_csv(train1_path, index=False)\n",
    "    te1.to_csv(test1_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Align TRAIN1 to TEST2 (reduce overlap)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Align TEST1 to TRAIN2 (reduce overlap)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "align_splits_oneside(\"../data/Japanese/Easy Japanese Extended_train.csv\", \"../data/Japanese/Easy Japanese Extended_val.csv\", \"../data/Japanese/Easy Japanese Corpus_train.csv\", \"../data/Japanese/Easy Japanese Corpus_val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------Japanese--------------\n",
      "TESTING ../data/Japanese/Easy Japanese Extended_train.csv vs ../data/Japanese/Easy Japanese Corpus_train.csv: BAD (8377 overlap original sentences) [MUST FIX!!!]\n",
      "TESTING ../data/Japanese/Easy Japanese Extended_train.csv vs ../data/Japanese/Easy Japanese Extended_test.csv: OKAY\n",
      "TESTING ../data/Japanese/Easy Japanese Extended_train.csv vs ../data/Japanese/Easy Japanese Corpus_val.csv: OKAY\n",
      "TESTING ../data/Japanese/Easy Japanese Extended_train.csv vs ../data/Japanese/Easy Japanese Corpus_test.csv: OKAY\n",
      "TESTING ../data/Japanese/Easy Japanese Extended_train.csv vs ../data/Japanese/Easy Japanese Extended_val.csv: OKAY\n",
      "TESTING ../data/Japanese/Easy Japanese Corpus_train.csv vs ../data/Japanese/Easy Japanese Extended_test.csv: OKAY\n",
      "TESTING ../data/Japanese/Easy Japanese Corpus_train.csv vs ../data/Japanese/Easy Japanese Corpus_val.csv: OKAY\n",
      "TESTING ../data/Japanese/Easy Japanese Corpus_train.csv vs ../data/Japanese/Easy Japanese Corpus_test.csv: OKAY\n",
      "TESTING ../data/Japanese/Easy Japanese Corpus_train.csv vs ../data/Japanese/Easy Japanese Extended_val.csv: OKAY\n",
      "TESTING ../data/Japanese/Easy Japanese Extended_test.csv vs ../data/Japanese/Easy Japanese Corpus_val.csv: OKAY\n",
      "TESTING ../data/Japanese/Easy Japanese Extended_test.csv vs ../data/Japanese/Easy Japanese Corpus_test.csv: BAD (26 overlap original sentences) [MUST FIX!!!]\n",
      "TESTING ../data/Japanese/Easy Japanese Extended_test.csv vs ../data/Japanese/Easy Japanese Extended_val.csv: OKAY\n",
      "TESTING ../data/Japanese/Easy Japanese Corpus_val.csv vs ../data/Japanese/Easy Japanese Corpus_test.csv: OKAY\n",
      "TESTING ../data/Japanese/Easy Japanese Corpus_val.csv vs ../data/Japanese/Easy Japanese Extended_val.csv: OKAY\n",
      "TESTING ../data/Japanese/Easy Japanese Corpus_test.csv vs ../data/Japanese/Easy Japanese Extended_val.csv: OKAY\n",
      "--------------German--------------\n",
      "TESTING ../data/German/TextComplexityDE Parallel Corpus_test.csv vs ../data/German/GEOLino Corpus_test.csv: OKAY\n",
      "TESTING ../data/German/TextComplexityDE Parallel Corpus_test.csv vs ../data/German/GEOLino Corpus_val.csv: OKAY\n",
      "TESTING ../data/German/TextComplexityDE Parallel Corpus_test.csv vs ../data/German/TextComplexityDE Parallel Corpus_val.csv: OKAY\n",
      "TESTING ../data/German/TextComplexityDE Parallel Corpus_test.csv vs ../data/German/GEOLino Corpus_train.csv: OKAY\n",
      "TESTING ../data/German/TextComplexityDE Parallel Corpus_test.csv vs ../data/German/German News_train.csv: OKAY\n",
      "TESTING ../data/German/TextComplexityDE Parallel Corpus_test.csv vs ../data/German/German News_test.csv: OKAY\n",
      "TESTING ../data/German/TextComplexityDE Parallel Corpus_test.csv vs ../data/German/German News_val.csv: OKAY\n",
      "TESTING ../data/German/TextComplexityDE Parallel Corpus_test.csv vs ../data/German/TextComplexityDE Parallel Corpus_train.csv: OKAY\n",
      "TESTING ../data/German/GEOLino Corpus_test.csv vs ../data/German/GEOLino Corpus_val.csv: OKAY\n",
      "TESTING ../data/German/GEOLino Corpus_test.csv vs ../data/German/TextComplexityDE Parallel Corpus_val.csv: OKAY\n",
      "TESTING ../data/German/GEOLino Corpus_test.csv vs ../data/German/GEOLino Corpus_train.csv: OKAY\n",
      "TESTING ../data/German/GEOLino Corpus_test.csv vs ../data/German/German News_train.csv: OKAY\n",
      "TESTING ../data/German/GEOLino Corpus_test.csv vs ../data/German/German News_test.csv: OKAY\n",
      "TESTING ../data/German/GEOLino Corpus_test.csv vs ../data/German/German News_val.csv: OKAY\n",
      "TESTING ../data/German/GEOLino Corpus_test.csv vs ../data/German/TextComplexityDE Parallel Corpus_train.csv: OKAY\n",
      "TESTING ../data/German/GEOLino Corpus_val.csv vs ../data/German/TextComplexityDE Parallel Corpus_val.csv: OKAY\n",
      "TESTING ../data/German/GEOLino Corpus_val.csv vs ../data/German/GEOLino Corpus_train.csv: OKAY\n",
      "TESTING ../data/German/GEOLino Corpus_val.csv vs ../data/German/German News_train.csv: OKAY\n",
      "TESTING ../data/German/GEOLino Corpus_val.csv vs ../data/German/German News_test.csv: OKAY\n",
      "TESTING ../data/German/GEOLino Corpus_val.csv vs ../data/German/German News_val.csv: OKAY\n",
      "TESTING ../data/German/GEOLino Corpus_val.csv vs ../data/German/TextComplexityDE Parallel Corpus_train.csv: OKAY\n",
      "TESTING ../data/German/TextComplexityDE Parallel Corpus_val.csv vs ../data/German/GEOLino Corpus_train.csv: OKAY\n",
      "TESTING ../data/German/TextComplexityDE Parallel Corpus_val.csv vs ../data/German/German News_train.csv: OKAY\n",
      "TESTING ../data/German/TextComplexityDE Parallel Corpus_val.csv vs ../data/German/German News_test.csv: OKAY\n",
      "TESTING ../data/German/TextComplexityDE Parallel Corpus_val.csv vs ../data/German/German News_val.csv: OKAY\n",
      "TESTING ../data/German/TextComplexityDE Parallel Corpus_val.csv vs ../data/German/TextComplexityDE Parallel Corpus_train.csv: OKAY\n",
      "TESTING ../data/German/GEOLino Corpus_train.csv vs ../data/German/German News_train.csv: OKAY\n",
      "TESTING ../data/German/GEOLino Corpus_train.csv vs ../data/German/German News_test.csv: OKAY\n",
      "TESTING ../data/German/GEOLino Corpus_train.csv vs ../data/German/German News_val.csv: OKAY\n",
      "TESTING ../data/German/GEOLino Corpus_train.csv vs ../data/German/TextComplexityDE Parallel Corpus_train.csv: OKAY\n",
      "TESTING ../data/German/German News_train.csv vs ../data/German/German News_test.csv: OKAY\n",
      "TESTING ../data/German/German News_train.csv vs ../data/German/German News_val.csv: OKAY\n",
      "TESTING ../data/German/German News_train.csv vs ../data/German/TextComplexityDE Parallel Corpus_train.csv: OKAY\n",
      "TESTING ../data/German/German News_test.csv vs ../data/German/German News_val.csv: OKAY\n",
      "TESTING ../data/German/German News_test.csv vs ../data/German/TextComplexityDE Parallel Corpus_train.csv: OKAY\n",
      "TESTING ../data/German/German News_val.csv vs ../data/German/TextComplexityDE Parallel Corpus_train.csv: OKAY\n",
      "--------------Slovene--------------\n",
      "TESTING ../data/Slovene/Text Simplification Slovene_test.csv vs ../data/Slovene/Text Simplification Slovene_train.csv: OKAY\n",
      "TESTING ../data/Slovene/Text Simplification Slovene_test.csv vs ../data/Slovene/Text Simplification Slovene_val.csv: OKAY\n",
      "TESTING ../data/Slovene/Text Simplification Slovene_train.csv vs ../data/Slovene/Text Simplification Slovene_val.csv: OKAY\n",
      "--------------Brazilian Portuguese--------------\n",
      "TESTING ../data/Brazilian Portuguese/PorSimples_val.csv vs ../data/Brazilian Portuguese/PorSimples_test.csv: OKAY\n",
      "TESTING ../data/Brazilian Portuguese/PorSimples_val.csv vs ../data/Brazilian Portuguese/PorSimples_train.csv: OKAY\n",
      "TESTING ../data/Brazilian Portuguese/PorSimples_test.csv vs ../data/Brazilian Portuguese/PorSimples_train.csv: OKAY\n",
      "--------------Urdu--------------\n",
      "TESTING ../data/Urdu/SimplifyUR_test.csv vs ../data/Urdu/SimplifyUR_train.csv: OKAY\n",
      "TESTING ../data/Urdu/SimplifyUR_test.csv vs ../data/Urdu/SimplifyUR_val.csv: OKAY\n",
      "TESTING ../data/Urdu/SimplifyUR_train.csv vs ../data/Urdu/SimplifyUR_val.csv: OKAY\n",
      "--------------Russian--------------\n",
      "TESTING ../data/Russian/RuWikiLarge_train.csv vs ../data/Russian/RSSE Corpus_val.csv: OKAY\n",
      "TESTING ../data/Russian/RuWikiLarge_train.csv vs ../data/Russian/RuWikiLarge_val.csv: OKAY\n",
      "TESTING ../data/Russian/RuWikiLarge_train.csv vs ../data/Russian/RuAdapt Ency_test.csv: OKAY\n",
      "TESTING ../data/Russian/RuWikiLarge_train.csv vs ../data/Russian/RuAdapt Fairytales_test.csv: OKAY\n",
      "TESTING ../data/Russian/RuWikiLarge_train.csv vs ../data/Russian/RuAdapt Ency_val.csv: OKAY\n",
      "TESTING ../data/Russian/RuWikiLarge_train.csv vs ../data/Russian/RuAdapt Literature_test.csv: OKAY\n",
      "TESTING ../data/Russian/RuWikiLarge_train.csv vs ../data/Russian/RuWikiLarge_test.csv: OKAY\n",
      "TESTING ../data/Russian/RuWikiLarge_train.csv vs ../data/Russian/RuAdapt Ency_train.csv: OKAY\n",
      "TESTING ../data/Russian/RuWikiLarge_train.csv vs ../data/Russian/RuAdapt Fairytales_val.csv: OKAY\n",
      "TESTING ../data/Russian/RuWikiLarge_train.csv vs ../data/Russian/RuAdapt Literature_val.csv: OKAY\n",
      "TESTING ../data/Russian/RuWikiLarge_train.csv vs ../data/Russian/RSSE Corpus_train.csv: OKAY\n",
      "TESTING ../data/Russian/RuWikiLarge_train.csv vs ../data/Russian/RuAdapt Fairytales_train.csv: OKAY\n",
      "TESTING ../data/Russian/RuWikiLarge_train.csv vs ../data/Russian/RSSE Corpus_test.csv: OKAY\n",
      "TESTING ../data/Russian/RuWikiLarge_train.csv vs ../data/Russian/RuAdapt Literature_train.csv: OKAY\n",
      "TESTING ../data/Russian/RSSE Corpus_val.csv vs ../data/Russian/RuWikiLarge_val.csv: OKAY\n",
      "TESTING ../data/Russian/RSSE Corpus_val.csv vs ../data/Russian/RuAdapt Ency_test.csv: OKAY\n",
      "TESTING ../data/Russian/RSSE Corpus_val.csv vs ../data/Russian/RuAdapt Fairytales_test.csv: OKAY\n",
      "TESTING ../data/Russian/RSSE Corpus_val.csv vs ../data/Russian/RuAdapt Ency_val.csv: OKAY\n",
      "TESTING ../data/Russian/RSSE Corpus_val.csv vs ../data/Russian/RuAdapt Literature_test.csv: OKAY\n",
      "TESTING ../data/Russian/RSSE Corpus_val.csv vs ../data/Russian/RuWikiLarge_test.csv: OKAY\n",
      "TESTING ../data/Russian/RSSE Corpus_val.csv vs ../data/Russian/RuAdapt Ency_train.csv: OKAY\n",
      "TESTING ../data/Russian/RSSE Corpus_val.csv vs ../data/Russian/RuAdapt Fairytales_val.csv: OKAY\n",
      "TESTING ../data/Russian/RSSE Corpus_val.csv vs ../data/Russian/RuAdapt Literature_val.csv: OKAY\n",
      "TESTING ../data/Russian/RSSE Corpus_val.csv vs ../data/Russian/RSSE Corpus_train.csv: OKAY\n",
      "TESTING ../data/Russian/RSSE Corpus_val.csv vs ../data/Russian/RuAdapt Fairytales_train.csv: OKAY\n",
      "TESTING ../data/Russian/RSSE Corpus_val.csv vs ../data/Russian/RSSE Corpus_test.csv: OKAY\n",
      "TESTING ../data/Russian/RSSE Corpus_val.csv vs ../data/Russian/RuAdapt Literature_train.csv: OKAY\n",
      "TESTING ../data/Russian/RuWikiLarge_val.csv vs ../data/Russian/RuAdapt Ency_test.csv: OKAY\n",
      "TESTING ../data/Russian/RuWikiLarge_val.csv vs ../data/Russian/RuAdapt Fairytales_test.csv: OKAY\n",
      "TESTING ../data/Russian/RuWikiLarge_val.csv vs ../data/Russian/RuAdapt Ency_val.csv: OKAY\n",
      "TESTING ../data/Russian/RuWikiLarge_val.csv vs ../data/Russian/RuAdapt Literature_test.csv: OKAY\n",
      "TESTING ../data/Russian/RuWikiLarge_val.csv vs ../data/Russian/RuWikiLarge_test.csv: OKAY\n",
      "TESTING ../data/Russian/RuWikiLarge_val.csv vs ../data/Russian/RuAdapt Ency_train.csv: OKAY\n",
      "TESTING ../data/Russian/RuWikiLarge_val.csv vs ../data/Russian/RuAdapt Fairytales_val.csv: OKAY\n",
      "TESTING ../data/Russian/RuWikiLarge_val.csv vs ../data/Russian/RuAdapt Literature_val.csv: OKAY\n",
      "TESTING ../data/Russian/RuWikiLarge_val.csv vs ../data/Russian/RSSE Corpus_train.csv: OKAY\n",
      "TESTING ../data/Russian/RuWikiLarge_val.csv vs ../data/Russian/RuAdapt Fairytales_train.csv: OKAY\n",
      "TESTING ../data/Russian/RuWikiLarge_val.csv vs ../data/Russian/RSSE Corpus_test.csv: OKAY\n",
      "TESTING ../data/Russian/RuWikiLarge_val.csv vs ../data/Russian/RuAdapt Literature_train.csv: OKAY\n",
      "TESTING ../data/Russian/RuAdapt Ency_test.csv vs ../data/Russian/RuAdapt Fairytales_test.csv: OKAY\n",
      "TESTING ../data/Russian/RuAdapt Ency_test.csv vs ../data/Russian/RuAdapt Ency_val.csv: OKAY\n",
      "TESTING ../data/Russian/RuAdapt Ency_test.csv vs ../data/Russian/RuAdapt Literature_test.csv: OKAY\n",
      "TESTING ../data/Russian/RuAdapt Ency_test.csv vs ../data/Russian/RuWikiLarge_test.csv: OKAY\n",
      "TESTING ../data/Russian/RuAdapt Ency_test.csv vs ../data/Russian/RuAdapt Ency_train.csv: OKAY\n",
      "TESTING ../data/Russian/RuAdapt Ency_test.csv vs ../data/Russian/RuAdapt Fairytales_val.csv: OKAY\n",
      "TESTING ../data/Russian/RuAdapt Ency_test.csv vs ../data/Russian/RuAdapt Literature_val.csv: OKAY\n",
      "TESTING ../data/Russian/RuAdapt Ency_test.csv vs ../data/Russian/RSSE Corpus_train.csv: OKAY\n",
      "TESTING ../data/Russian/RuAdapt Ency_test.csv vs ../data/Russian/RuAdapt Fairytales_train.csv: OKAY\n",
      "TESTING ../data/Russian/RuAdapt Ency_test.csv vs ../data/Russian/RSSE Corpus_test.csv: OKAY\n",
      "TESTING ../data/Russian/RuAdapt Ency_test.csv vs ../data/Russian/RuAdapt Literature_train.csv: OKAY\n",
      "TESTING ../data/Russian/RuAdapt Fairytales_test.csv vs ../data/Russian/RuAdapt Ency_val.csv: OKAY\n",
      "TESTING ../data/Russian/RuAdapt Fairytales_test.csv vs ../data/Russian/RuAdapt Literature_test.csv: OKAY\n",
      "TESTING ../data/Russian/RuAdapt Fairytales_test.csv vs ../data/Russian/RuWikiLarge_test.csv: OKAY\n",
      "TESTING ../data/Russian/RuAdapt Fairytales_test.csv vs ../data/Russian/RuAdapt Ency_train.csv: OKAY\n",
      "TESTING ../data/Russian/RuAdapt Fairytales_test.csv vs ../data/Russian/RuAdapt Fairytales_val.csv: OKAY\n",
      "TESTING ../data/Russian/RuAdapt Fairytales_test.csv vs ../data/Russian/RuAdapt Literature_val.csv: OKAY\n",
      "TESTING ../data/Russian/RuAdapt Fairytales_test.csv vs ../data/Russian/RSSE Corpus_train.csv: OKAY\n",
      "TESTING ../data/Russian/RuAdapt Fairytales_test.csv vs ../data/Russian/RuAdapt Fairytales_train.csv: OKAY\n",
      "TESTING ../data/Russian/RuAdapt Fairytales_test.csv vs ../data/Russian/RSSE Corpus_test.csv: OKAY\n",
      "TESTING ../data/Russian/RuAdapt Fairytales_test.csv vs ../data/Russian/RuAdapt Literature_train.csv: OKAY\n",
      "TESTING ../data/Russian/RuAdapt Ency_val.csv vs ../data/Russian/RuAdapt Literature_test.csv: OKAY\n",
      "TESTING ../data/Russian/RuAdapt Ency_val.csv vs ../data/Russian/RuWikiLarge_test.csv: OKAY\n",
      "TESTING ../data/Russian/RuAdapt Ency_val.csv vs ../data/Russian/RuAdapt Ency_train.csv: OKAY\n",
      "TESTING ../data/Russian/RuAdapt Ency_val.csv vs ../data/Russian/RuAdapt Fairytales_val.csv: OKAY\n",
      "TESTING ../data/Russian/RuAdapt Ency_val.csv vs ../data/Russian/RuAdapt Literature_val.csv: OKAY\n",
      "TESTING ../data/Russian/RuAdapt Ency_val.csv vs ../data/Russian/RSSE Corpus_train.csv: OKAY\n",
      "TESTING ../data/Russian/RuAdapt Ency_val.csv vs ../data/Russian/RuAdapt Fairytales_train.csv: OKAY\n",
      "TESTING ../data/Russian/RuAdapt Ency_val.csv vs ../data/Russian/RSSE Corpus_test.csv: OKAY\n",
      "TESTING ../data/Russian/RuAdapt Ency_val.csv vs ../data/Russian/RuAdapt Literature_train.csv: OKAY\n",
      "TESTING ../data/Russian/RuAdapt Literature_test.csv vs ../data/Russian/RuWikiLarge_test.csv: OKAY\n",
      "TESTING ../data/Russian/RuAdapt Literature_test.csv vs ../data/Russian/RuAdapt Ency_train.csv: OKAY\n",
      "TESTING ../data/Russian/RuAdapt Literature_test.csv vs ../data/Russian/RuAdapt Fairytales_val.csv: OKAY\n",
      "TESTING ../data/Russian/RuAdapt Literature_test.csv vs ../data/Russian/RuAdapt Literature_val.csv: OKAY\n",
      "TESTING ../data/Russian/RuAdapt Literature_test.csv vs ../data/Russian/RSSE Corpus_train.csv: OKAY\n",
      "TESTING ../data/Russian/RuAdapt Literature_test.csv vs ../data/Russian/RuAdapt Fairytales_train.csv: OKAY\n",
      "TESTING ../data/Russian/RuAdapt Literature_test.csv vs ../data/Russian/RSSE Corpus_test.csv: OKAY\n",
      "TESTING ../data/Russian/RuAdapt Literature_test.csv vs ../data/Russian/RuAdapt Literature_train.csv: OKAY\n",
      "TESTING ../data/Russian/RuWikiLarge_test.csv vs ../data/Russian/RuAdapt Ency_train.csv: OKAY\n",
      "TESTING ../data/Russian/RuWikiLarge_test.csv vs ../data/Russian/RuAdapt Fairytales_val.csv: OKAY\n",
      "TESTING ../data/Russian/RuWikiLarge_test.csv vs ../data/Russian/RuAdapt Literature_val.csv: OKAY\n",
      "TESTING ../data/Russian/RuWikiLarge_test.csv vs ../data/Russian/RSSE Corpus_train.csv: OKAY\n",
      "TESTING ../data/Russian/RuWikiLarge_test.csv vs ../data/Russian/RuAdapt Fairytales_train.csv: OKAY\n",
      "TESTING ../data/Russian/RuWikiLarge_test.csv vs ../data/Russian/RSSE Corpus_test.csv: OKAY\n",
      "TESTING ../data/Russian/RuWikiLarge_test.csv vs ../data/Russian/RuAdapt Literature_train.csv: OKAY\n",
      "TESTING ../data/Russian/RuAdapt Ency_train.csv vs ../data/Russian/RuAdapt Fairytales_val.csv: OKAY\n",
      "TESTING ../data/Russian/RuAdapt Ency_train.csv vs ../data/Russian/RuAdapt Literature_val.csv: OKAY\n",
      "TESTING ../data/Russian/RuAdapt Ency_train.csv vs ../data/Russian/RSSE Corpus_train.csv: OKAY\n",
      "TESTING ../data/Russian/RuAdapt Ency_train.csv vs ../data/Russian/RuAdapt Fairytales_train.csv: OKAY\n",
      "TESTING ../data/Russian/RuAdapt Ency_train.csv vs ../data/Russian/RSSE Corpus_test.csv: OKAY\n",
      "TESTING ../data/Russian/RuAdapt Ency_train.csv vs ../data/Russian/RuAdapt Literature_train.csv: BAD (11 overlap original sentences) [MUST FIX!!!]\n",
      "TESTING ../data/Russian/RuAdapt Fairytales_val.csv vs ../data/Russian/RuAdapt Literature_val.csv: OKAY\n",
      "TESTING ../data/Russian/RuAdapt Fairytales_val.csv vs ../data/Russian/RSSE Corpus_train.csv: OKAY\n",
      "TESTING ../data/Russian/RuAdapt Fairytales_val.csv vs ../data/Russian/RuAdapt Fairytales_train.csv: OKAY\n",
      "TESTING ../data/Russian/RuAdapt Fairytales_val.csv vs ../data/Russian/RSSE Corpus_test.csv: OKAY\n",
      "TESTING ../data/Russian/RuAdapt Fairytales_val.csv vs ../data/Russian/RuAdapt Literature_train.csv: OKAY\n",
      "TESTING ../data/Russian/RuAdapt Literature_val.csv vs ../data/Russian/RSSE Corpus_train.csv: OKAY\n",
      "TESTING ../data/Russian/RuAdapt Literature_val.csv vs ../data/Russian/RuAdapt Fairytales_train.csv: OKAY\n",
      "TESTING ../data/Russian/RuAdapt Literature_val.csv vs ../data/Russian/RSSE Corpus_test.csv: OKAY\n",
      "TESTING ../data/Russian/RuAdapt Literature_val.csv vs ../data/Russian/RuAdapt Literature_train.csv: OKAY\n",
      "TESTING ../data/Russian/RSSE Corpus_train.csv vs ../data/Russian/RuAdapt Fairytales_train.csv: OKAY\n",
      "TESTING ../data/Russian/RSSE Corpus_train.csv vs ../data/Russian/RSSE Corpus_test.csv: OKAY\n",
      "TESTING ../data/Russian/RSSE Corpus_train.csv vs ../data/Russian/RuAdapt Literature_train.csv: OKAY\n",
      "TESTING ../data/Russian/RuAdapt Fairytales_train.csv vs ../data/Russian/RSSE Corpus_test.csv: OKAY\n",
      "TESTING ../data/Russian/RuAdapt Fairytales_train.csv vs ../data/Russian/RuAdapt Literature_train.csv: OKAY\n",
      "TESTING ../data/Russian/RSSE Corpus_test.csv vs ../data/Russian/RuAdapt Literature_train.csv: OKAY\n",
      "--------------Italian--------------\n",
      "TESTING ../data/Italian/Teacher_train.csv vs ../data/Italian/AdminIT_test.csv: OKAY\n",
      "TESTING ../data/Italian/Teacher_train.csv vs ../data/Italian/Terence_val.csv: OKAY\n",
      "TESTING ../data/Italian/Teacher_train.csv vs ../data/Italian/Simpitiki Italian Wikipedia_train.csv: OKAY\n",
      "TESTING ../data/Italian/Teacher_train.csv vs ../data/Italian/AdminIT_train.csv: OKAY\n",
      "TESTING ../data/Italian/Teacher_train.csv vs ../data/Italian/PaCCSS-IT Corpus_train.csv: OKAY\n",
      "TESTING ../data/Italian/Teacher_train.csv vs ../data/Italian/AdminIT_val.csv: OKAY\n",
      "TESTING ../data/Italian/Teacher_train.csv vs ../data/Italian/PaCCSS-IT Corpus_test.csv: OKAY\n",
      "TESTING ../data/Italian/Teacher_train.csv vs ../data/Italian/Terence_test.csv: OKAY\n",
      "TESTING ../data/Italian/Teacher_train.csv vs ../data/Italian/Simpitiki Italian Wikipedia_val.csv: OKAY\n",
      "TESTING ../data/Italian/Teacher_train.csv vs ../data/Italian/Teacher_val.csv: OKAY\n",
      "TESTING ../data/Italian/Teacher_train.csv vs ../data/Italian/Teacher_test.csv: OKAY\n",
      "TESTING ../data/Italian/Teacher_train.csv vs ../data/Italian/Terence_train.csv: OKAY\n",
      "TESTING ../data/Italian/Teacher_train.csv vs ../data/Italian/PaCCSS-IT Corpus_val.csv: OKAY\n",
      "TESTING ../data/Italian/Teacher_train.csv vs ../data/Italian/Simpitiki Italian Wikipedia_test.csv: OKAY\n",
      "TESTING ../data/Italian/AdminIT_test.csv vs ../data/Italian/Terence_val.csv: OKAY\n",
      "TESTING ../data/Italian/AdminIT_test.csv vs ../data/Italian/Simpitiki Italian Wikipedia_train.csv: OKAY\n",
      "TESTING ../data/Italian/AdminIT_test.csv vs ../data/Italian/AdminIT_train.csv: OKAY\n",
      "TESTING ../data/Italian/AdminIT_test.csv vs ../data/Italian/PaCCSS-IT Corpus_train.csv: OKAY\n",
      "TESTING ../data/Italian/AdminIT_test.csv vs ../data/Italian/AdminIT_val.csv: OKAY\n",
      "TESTING ../data/Italian/AdminIT_test.csv vs ../data/Italian/PaCCSS-IT Corpus_test.csv: OKAY\n",
      "TESTING ../data/Italian/AdminIT_test.csv vs ../data/Italian/Terence_test.csv: OKAY\n",
      "TESTING ../data/Italian/AdminIT_test.csv vs ../data/Italian/Simpitiki Italian Wikipedia_val.csv: OKAY\n",
      "TESTING ../data/Italian/AdminIT_test.csv vs ../data/Italian/Teacher_val.csv: OKAY\n",
      "TESTING ../data/Italian/AdminIT_test.csv vs ../data/Italian/Teacher_test.csv: OKAY\n",
      "TESTING ../data/Italian/AdminIT_test.csv vs ../data/Italian/Terence_train.csv: OKAY\n",
      "TESTING ../data/Italian/AdminIT_test.csv vs ../data/Italian/PaCCSS-IT Corpus_val.csv: OKAY\n",
      "TESTING ../data/Italian/AdminIT_test.csv vs ../data/Italian/Simpitiki Italian Wikipedia_test.csv: OKAY\n",
      "TESTING ../data/Italian/Terence_val.csv vs ../data/Italian/Simpitiki Italian Wikipedia_train.csv: OKAY\n",
      "TESTING ../data/Italian/Terence_val.csv vs ../data/Italian/AdminIT_train.csv: OKAY\n",
      "TESTING ../data/Italian/Terence_val.csv vs ../data/Italian/PaCCSS-IT Corpus_train.csv: OKAY\n",
      "TESTING ../data/Italian/Terence_val.csv vs ../data/Italian/AdminIT_val.csv: OKAY\n",
      "TESTING ../data/Italian/Terence_val.csv vs ../data/Italian/PaCCSS-IT Corpus_test.csv: OKAY\n",
      "TESTING ../data/Italian/Terence_val.csv vs ../data/Italian/Terence_test.csv: OKAY\n",
      "TESTING ../data/Italian/Terence_val.csv vs ../data/Italian/Simpitiki Italian Wikipedia_val.csv: OKAY\n",
      "TESTING ../data/Italian/Terence_val.csv vs ../data/Italian/Teacher_val.csv: OKAY\n",
      "TESTING ../data/Italian/Terence_val.csv vs ../data/Italian/Teacher_test.csv: OKAY\n",
      "TESTING ../data/Italian/Terence_val.csv vs ../data/Italian/Terence_train.csv: OKAY\n",
      "TESTING ../data/Italian/Terence_val.csv vs ../data/Italian/PaCCSS-IT Corpus_val.csv: OKAY\n",
      "TESTING ../data/Italian/Terence_val.csv vs ../data/Italian/Simpitiki Italian Wikipedia_test.csv: OKAY\n",
      "TESTING ../data/Italian/Simpitiki Italian Wikipedia_train.csv vs ../data/Italian/AdminIT_train.csv: OKAY\n",
      "TESTING ../data/Italian/Simpitiki Italian Wikipedia_train.csv vs ../data/Italian/PaCCSS-IT Corpus_train.csv: OKAY\n",
      "TESTING ../data/Italian/Simpitiki Italian Wikipedia_train.csv vs ../data/Italian/AdminIT_val.csv: OKAY\n",
      "TESTING ../data/Italian/Simpitiki Italian Wikipedia_train.csv vs ../data/Italian/PaCCSS-IT Corpus_test.csv: OKAY\n",
      "TESTING ../data/Italian/Simpitiki Italian Wikipedia_train.csv vs ../data/Italian/Terence_test.csv: OKAY\n",
      "TESTING ../data/Italian/Simpitiki Italian Wikipedia_train.csv vs ../data/Italian/Simpitiki Italian Wikipedia_val.csv: OKAY\n",
      "TESTING ../data/Italian/Simpitiki Italian Wikipedia_train.csv vs ../data/Italian/Teacher_val.csv: OKAY\n",
      "TESTING ../data/Italian/Simpitiki Italian Wikipedia_train.csv vs ../data/Italian/Teacher_test.csv: OKAY\n",
      "TESTING ../data/Italian/Simpitiki Italian Wikipedia_train.csv vs ../data/Italian/Terence_train.csv: OKAY\n",
      "TESTING ../data/Italian/Simpitiki Italian Wikipedia_train.csv vs ../data/Italian/PaCCSS-IT Corpus_val.csv: OKAY\n",
      "TESTING ../data/Italian/Simpitiki Italian Wikipedia_train.csv vs ../data/Italian/Simpitiki Italian Wikipedia_test.csv: OKAY\n",
      "TESTING ../data/Italian/AdminIT_train.csv vs ../data/Italian/PaCCSS-IT Corpus_train.csv: OKAY\n",
      "TESTING ../data/Italian/AdminIT_train.csv vs ../data/Italian/AdminIT_val.csv: OKAY\n",
      "TESTING ../data/Italian/AdminIT_train.csv vs ../data/Italian/PaCCSS-IT Corpus_test.csv: OKAY\n",
      "TESTING ../data/Italian/AdminIT_train.csv vs ../data/Italian/Terence_test.csv: OKAY\n",
      "TESTING ../data/Italian/AdminIT_train.csv vs ../data/Italian/Simpitiki Italian Wikipedia_val.csv: OKAY\n",
      "TESTING ../data/Italian/AdminIT_train.csv vs ../data/Italian/Teacher_val.csv: OKAY\n",
      "TESTING ../data/Italian/AdminIT_train.csv vs ../data/Italian/Teacher_test.csv: OKAY\n",
      "TESTING ../data/Italian/AdminIT_train.csv vs ../data/Italian/Terence_train.csv: OKAY\n",
      "TESTING ../data/Italian/AdminIT_train.csv vs ../data/Italian/PaCCSS-IT Corpus_val.csv: OKAY\n",
      "TESTING ../data/Italian/AdminIT_train.csv vs ../data/Italian/Simpitiki Italian Wikipedia_test.csv: OKAY\n",
      "TESTING ../data/Italian/PaCCSS-IT Corpus_train.csv vs ../data/Italian/AdminIT_val.csv: OKAY\n",
      "TESTING ../data/Italian/PaCCSS-IT Corpus_train.csv vs ../data/Italian/PaCCSS-IT Corpus_test.csv: OKAY\n",
      "TESTING ../data/Italian/PaCCSS-IT Corpus_train.csv vs ../data/Italian/Terence_test.csv: OKAY\n",
      "TESTING ../data/Italian/PaCCSS-IT Corpus_train.csv vs ../data/Italian/Simpitiki Italian Wikipedia_val.csv: OKAY\n",
      "TESTING ../data/Italian/PaCCSS-IT Corpus_train.csv vs ../data/Italian/Teacher_val.csv: OKAY\n",
      "TESTING ../data/Italian/PaCCSS-IT Corpus_train.csv vs ../data/Italian/Teacher_test.csv: OKAY\n",
      "TESTING ../data/Italian/PaCCSS-IT Corpus_train.csv vs ../data/Italian/Terence_train.csv: OKAY\n",
      "TESTING ../data/Italian/PaCCSS-IT Corpus_train.csv vs ../data/Italian/PaCCSS-IT Corpus_val.csv: OKAY\n",
      "TESTING ../data/Italian/PaCCSS-IT Corpus_train.csv vs ../data/Italian/Simpitiki Italian Wikipedia_test.csv: OKAY\n",
      "TESTING ../data/Italian/AdminIT_val.csv vs ../data/Italian/PaCCSS-IT Corpus_test.csv: OKAY\n",
      "TESTING ../data/Italian/AdminIT_val.csv vs ../data/Italian/Terence_test.csv: OKAY\n",
      "TESTING ../data/Italian/AdminIT_val.csv vs ../data/Italian/Simpitiki Italian Wikipedia_val.csv: OKAY\n",
      "TESTING ../data/Italian/AdminIT_val.csv vs ../data/Italian/Teacher_val.csv: OKAY\n",
      "TESTING ../data/Italian/AdminIT_val.csv vs ../data/Italian/Teacher_test.csv: OKAY\n",
      "TESTING ../data/Italian/AdminIT_val.csv vs ../data/Italian/Terence_train.csv: OKAY\n",
      "TESTING ../data/Italian/AdminIT_val.csv vs ../data/Italian/PaCCSS-IT Corpus_val.csv: OKAY\n",
      "TESTING ../data/Italian/AdminIT_val.csv vs ../data/Italian/Simpitiki Italian Wikipedia_test.csv: OKAY\n",
      "TESTING ../data/Italian/PaCCSS-IT Corpus_test.csv vs ../data/Italian/Terence_test.csv: OKAY\n",
      "TESTING ../data/Italian/PaCCSS-IT Corpus_test.csv vs ../data/Italian/Simpitiki Italian Wikipedia_val.csv: OKAY\n",
      "TESTING ../data/Italian/PaCCSS-IT Corpus_test.csv vs ../data/Italian/Teacher_val.csv: OKAY\n",
      "TESTING ../data/Italian/PaCCSS-IT Corpus_test.csv vs ../data/Italian/Teacher_test.csv: OKAY\n",
      "TESTING ../data/Italian/PaCCSS-IT Corpus_test.csv vs ../data/Italian/Terence_train.csv: OKAY\n",
      "TESTING ../data/Italian/PaCCSS-IT Corpus_test.csv vs ../data/Italian/PaCCSS-IT Corpus_val.csv: OKAY\n",
      "TESTING ../data/Italian/PaCCSS-IT Corpus_test.csv vs ../data/Italian/Simpitiki Italian Wikipedia_test.csv: OKAY\n",
      "TESTING ../data/Italian/Terence_test.csv vs ../data/Italian/Simpitiki Italian Wikipedia_val.csv: OKAY\n",
      "TESTING ../data/Italian/Terence_test.csv vs ../data/Italian/Teacher_val.csv: OKAY\n",
      "TESTING ../data/Italian/Terence_test.csv vs ../data/Italian/Teacher_test.csv: OKAY\n",
      "TESTING ../data/Italian/Terence_test.csv vs ../data/Italian/Terence_train.csv: OKAY\n",
      "TESTING ../data/Italian/Terence_test.csv vs ../data/Italian/PaCCSS-IT Corpus_val.csv: OKAY\n",
      "TESTING ../data/Italian/Terence_test.csv vs ../data/Italian/Simpitiki Italian Wikipedia_test.csv: OKAY\n",
      "TESTING ../data/Italian/Simpitiki Italian Wikipedia_val.csv vs ../data/Italian/Teacher_val.csv: OKAY\n",
      "TESTING ../data/Italian/Simpitiki Italian Wikipedia_val.csv vs ../data/Italian/Teacher_test.csv: OKAY\n",
      "TESTING ../data/Italian/Simpitiki Italian Wikipedia_val.csv vs ../data/Italian/Terence_train.csv: OKAY\n",
      "TESTING ../data/Italian/Simpitiki Italian Wikipedia_val.csv vs ../data/Italian/PaCCSS-IT Corpus_val.csv: OKAY\n",
      "TESTING ../data/Italian/Simpitiki Italian Wikipedia_val.csv vs ../data/Italian/Simpitiki Italian Wikipedia_test.csv: OKAY\n",
      "TESTING ../data/Italian/Teacher_val.csv vs ../data/Italian/Teacher_test.csv: OKAY\n",
      "TESTING ../data/Italian/Teacher_val.csv vs ../data/Italian/Terence_train.csv: OKAY\n",
      "TESTING ../data/Italian/Teacher_val.csv vs ../data/Italian/PaCCSS-IT Corpus_val.csv: OKAY\n",
      "TESTING ../data/Italian/Teacher_val.csv vs ../data/Italian/Simpitiki Italian Wikipedia_test.csv: OKAY\n",
      "TESTING ../data/Italian/Teacher_test.csv vs ../data/Italian/Terence_train.csv: OKAY\n",
      "TESTING ../data/Italian/Teacher_test.csv vs ../data/Italian/PaCCSS-IT Corpus_val.csv: OKAY\n",
      "TESTING ../data/Italian/Teacher_test.csv vs ../data/Italian/Simpitiki Italian Wikipedia_test.csv: OKAY\n",
      "TESTING ../data/Italian/Terence_train.csv vs ../data/Italian/PaCCSS-IT Corpus_val.csv: OKAY\n",
      "TESTING ../data/Italian/Terence_train.csv vs ../data/Italian/Simpitiki Italian Wikipedia_test.csv: OKAY\n",
      "TESTING ../data/Italian/PaCCSS-IT Corpus_val.csv vs ../data/Italian/Simpitiki Italian Wikipedia_test.csv: OKAY\n",
      "--------------English--------------\n",
      "TESTING ../data/English/WikiAuto_train.csv vs ../data/English/ASSET_train.csv: BAD (3240 overlap original sentences) [MUST FIX!!!]\n",
      "TESTING ../data/English/WikiAuto_train.csv vs ../data/English/ASSET_val.csv: OKAY\n",
      "TESTING ../data/English/WikiAuto_train.csv vs ../data/English/Newsela EN_train.csv: BAD (15 overlap original sentences) [MUST FIX!!!]\n",
      "TESTING ../data/English/WikiAuto_train.csv vs ../data/English/ASSET_test.csv: OKAY\n",
      "TESTING ../data/English/WikiAuto_train.csv vs ../data/English/WikiAuto_test.csv: OKAY\n",
      "TESTING ../data/English/WikiAuto_train.csv vs ../data/English/Newsela EN_val.csv: OKAY\n",
      "TESTING ../data/English/WikiAuto_train.csv vs ../data/English/Newsela EN_test.csv: OKAY\n",
      "TESTING ../data/English/WikiAuto_train.csv vs ../data/English/WikiAuto_val.csv: OKAY\n",
      "TESTING ../data/English/ASSET_train.csv vs ../data/English/ASSET_val.csv: OKAY\n",
      "TESTING ../data/English/ASSET_train.csv vs ../data/English/Newsela EN_train.csv: OKAY\n",
      "TESTING ../data/English/ASSET_train.csv vs ../data/English/ASSET_test.csv: OKAY\n",
      "TESTING ../data/English/ASSET_train.csv vs ../data/English/WikiAuto_test.csv: OKAY\n",
      "TESTING ../data/English/ASSET_train.csv vs ../data/English/Newsela EN_val.csv: OKAY\n",
      "TESTING ../data/English/ASSET_train.csv vs ../data/English/Newsela EN_test.csv: OKAY\n",
      "TESTING ../data/English/ASSET_train.csv vs ../data/English/WikiAuto_val.csv: OKAY\n",
      "TESTING ../data/English/ASSET_val.csv vs ../data/English/Newsela EN_train.csv: OKAY\n",
      "TESTING ../data/English/ASSET_val.csv vs ../data/English/ASSET_test.csv: OKAY\n",
      "TESTING ../data/English/ASSET_val.csv vs ../data/English/WikiAuto_test.csv: OKAY\n",
      "TESTING ../data/English/ASSET_val.csv vs ../data/English/Newsela EN_val.csv: OKAY\n",
      "TESTING ../data/English/ASSET_val.csv vs ../data/English/Newsela EN_test.csv: OKAY\n",
      "TESTING ../data/English/ASSET_val.csv vs ../data/English/WikiAuto_val.csv: OKAY\n",
      "TESTING ../data/English/Newsela EN_train.csv vs ../data/English/ASSET_test.csv: OKAY\n",
      "TESTING ../data/English/Newsela EN_train.csv vs ../data/English/WikiAuto_test.csv: OKAY\n",
      "TESTING ../data/English/Newsela EN_train.csv vs ../data/English/Newsela EN_val.csv: OKAY\n",
      "TESTING ../data/English/Newsela EN_train.csv vs ../data/English/Newsela EN_test.csv: OKAY\n",
      "TESTING ../data/English/Newsela EN_train.csv vs ../data/English/WikiAuto_val.csv: OKAY\n",
      "TESTING ../data/English/ASSET_test.csv vs ../data/English/WikiAuto_test.csv: BAD (64 overlap original sentences) [MUST FIX!!!]\n",
      "TESTING ../data/English/ASSET_test.csv vs ../data/English/Newsela EN_val.csv: OKAY\n",
      "TESTING ../data/English/ASSET_test.csv vs ../data/English/Newsela EN_test.csv: OKAY\n",
      "TESTING ../data/English/ASSET_test.csv vs ../data/English/WikiAuto_val.csv: OKAY\n",
      "TESTING ../data/English/WikiAuto_test.csv vs ../data/English/Newsela EN_val.csv: OKAY\n",
      "TESTING ../data/English/WikiAuto_test.csv vs ../data/English/Newsela EN_test.csv: OKAY\n",
      "TESTING ../data/English/WikiAuto_test.csv vs ../data/English/WikiAuto_val.csv: OKAY\n",
      "TESTING ../data/English/Newsela EN_val.csv vs ../data/English/Newsela EN_test.csv: OKAY\n",
      "TESTING ../data/English/Newsela EN_val.csv vs ../data/English/WikiAuto_val.csv: OKAY\n",
      "TESTING ../data/English/Newsela EN_test.csv vs ../data/English/WikiAuto_val.csv: OKAY\n",
      "--------------Danish--------------\n",
      "TESTING ../data/Danish/DSim Corpus_test.csv vs ../data/Danish/DSim Corpus_train.csv: OKAY\n",
      "TESTING ../data/Danish/DSim Corpus_test.csv vs ../data/Danish/DSim Corpus_val.csv: OKAY\n",
      "TESTING ../data/Danish/DSim Corpus_train.csv vs ../data/Danish/DSim Corpus_val.csv: OKAY\n",
      "--------------French--------------\n",
      "TESTING ../data/French/CLEAR Corpus_test.csv vs ../data/French/WikiLargeFR Corpus_test.csv: OKAY\n",
      "TESTING ../data/French/CLEAR Corpus_test.csv vs ../data/French/WikiLargeFR Corpus_train.csv: OKAY\n",
      "TESTING ../data/French/CLEAR Corpus_test.csv vs ../data/French/WikiLargeFR Corpus_val.csv: OKAY\n",
      "TESTING ../data/French/CLEAR Corpus_test.csv vs ../data/French/CLEAR Corpus_train.csv: OKAY\n",
      "TESTING ../data/French/CLEAR Corpus_test.csv vs ../data/French/CLEAR Corpus_val.csv: OKAY\n",
      "TESTING ../data/French/WikiLargeFR Corpus_test.csv vs ../data/French/WikiLargeFR Corpus_train.csv: OKAY\n",
      "TESTING ../data/French/WikiLargeFR Corpus_test.csv vs ../data/French/WikiLargeFR Corpus_val.csv: OKAY\n",
      "TESTING ../data/French/WikiLargeFR Corpus_test.csv vs ../data/French/CLEAR Corpus_train.csv: OKAY\n",
      "TESTING ../data/French/WikiLargeFR Corpus_test.csv vs ../data/French/CLEAR Corpus_val.csv: OKAY\n",
      "TESTING ../data/French/WikiLargeFR Corpus_train.csv vs ../data/French/WikiLargeFR Corpus_val.csv: OKAY\n",
      "TESTING ../data/French/WikiLargeFR Corpus_train.csv vs ../data/French/CLEAR Corpus_train.csv: OKAY\n",
      "TESTING ../data/French/WikiLargeFR Corpus_train.csv vs ../data/French/CLEAR Corpus_val.csv: OKAY\n",
      "TESTING ../data/French/WikiLargeFR Corpus_val.csv vs ../data/French/CLEAR Corpus_train.csv: OKAY\n",
      "TESTING ../data/French/WikiLargeFR Corpus_val.csv vs ../data/French/CLEAR Corpus_val.csv: OKAY\n",
      "TESTING ../data/French/CLEAR Corpus_train.csv vs ../data/French/CLEAR Corpus_val.csv: OKAY\n",
      "--------------Spanish--------------\n",
      "TESTING ../data/Spanish/Newsela ES_test.csv vs ../data/Spanish/Newsela ES_val.csv: OKAY\n",
      "TESTING ../data/Spanish/Newsela ES_test.csv vs ../data/Spanish/Simplext_val.csv: OKAY\n",
      "TESTING ../data/Spanish/Newsela ES_test.csv vs ../data/Spanish/Simplext_test.csv: OKAY\n",
      "TESTING ../data/Spanish/Newsela ES_test.csv vs ../data/Spanish/Newsela ES_train.csv: OKAY\n",
      "TESTING ../data/Spanish/Newsela ES_test.csv vs ../data/Spanish/Simplext_train.csv: OKAY\n",
      "TESTING ../data/Spanish/Newsela ES_val.csv vs ../data/Spanish/Simplext_val.csv: OKAY\n",
      "TESTING ../data/Spanish/Newsela ES_val.csv vs ../data/Spanish/Simplext_test.csv: OKAY\n",
      "TESTING ../data/Spanish/Newsela ES_val.csv vs ../data/Spanish/Newsela ES_train.csv: OKAY\n",
      "TESTING ../data/Spanish/Newsela ES_val.csv vs ../data/Spanish/Simplext_train.csv: OKAY\n",
      "TESTING ../data/Spanish/Simplext_val.csv vs ../data/Spanish/Simplext_test.csv: OKAY\n",
      "TESTING ../data/Spanish/Simplext_val.csv vs ../data/Spanish/Newsela ES_train.csv: OKAY\n",
      "TESTING ../data/Spanish/Simplext_val.csv vs ../data/Spanish/Simplext_train.csv: OKAY\n",
      "TESTING ../data/Spanish/Simplext_test.csv vs ../data/Spanish/Newsela ES_train.csv: OKAY\n",
      "TESTING ../data/Spanish/Simplext_test.csv vs ../data/Spanish/Simplext_train.csv: OKAY\n",
      "TESTING ../data/Spanish/Newsela ES_train.csv vs ../data/Spanish/Simplext_train.csv: OKAY\n",
      "--------------Basque--------------\n",
      "TESTING ../data/Basque/CBST_test.csv vs ../data/Basque/SimplifyUR_test_experiment.csv: OKAY\n",
      "TESTING ../data/Basque/CBST_test.csv vs ../data/Basque/CBST_train.csv: OKAY\n",
      "TESTING ../data/Basque/CBST_test.csv vs ../data/Basque/CBST_val.csv: OKAY\n",
      "TESTING ../data/Basque/SimplifyUR_test_experiment.csv vs ../data/Basque/CBST_train.csv: OKAY\n",
      "TESTING ../data/Basque/SimplifyUR_test_experiment.csv vs ../data/Basque/CBST_val.csv: OKAY\n",
      "TESTING ../data/Basque/CBST_train.csv vs ../data/Basque/CBST_val.csv: OKAY\n"
     ]
    }
   ],
   "source": [
    "check_overlap_all_data(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assertFrameEqual(df1, df2, **kwds ):\n",
    "    \"\"\" Assert that two dataframes are equal, ignoring ordering of columns\"\"\"\n",
    "    from pandas.util.testing import assert_frame_equal\n",
    "    return assert_frame_equal(df1.sort_index(axis=1), df2.sort_index(axis=1), check_names=True, **kwds )\n",
    "\n",
    "def check_equivalent(new_train_path, new_test_path, new_val_path, old_train_path, old_test_path):\n",
    "    tr1, te1, tr2, te2 = [pd.read_csv(path) for path in [new_train_path, new_test_path, old_train_path, old_test_path]]\n",
    "    new_list = [tr1, te1]\n",
    "    if not new_val_path == \"\" and os.path.exists(new_val_path):\n",
    "        va1 = pd.read_csv(new_val_path)\n",
    "        new_list.append(va1)\n",
    "    new = pd.concat(new_list, ignore_index=True).sort_values(by=['original', 'simple']).reset_index(drop=True)\n",
    "    old = pd.concat([tr2, te2], ignore_index=True).sort_values(by=['original', 'simple']).reset_index(drop=True)\n",
    "    try:\n",
    "        assertFrameEqual(new,old)\n",
    "        return True\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that nothing in broken\n",
    "def check_equivalent_all_data(directory, old_directory):\n",
    "    print(\"Many will say bad once the references have been grouped.  Run this on ungrouped references for accurate results\")\n",
    "    for dir_name in os.listdir(directory):\n",
    "        dir = os.path.join(directory, dir_name)\n",
    "        if os.path.isdir(dir):\n",
    "            print(\"--------------\" + dir_name + \"--------------\")\n",
    "            for file in os.listdir(dir):\n",
    "                data_file = os.path.join(dir,file)\n",
    "                if(os.path.isfile(data_file) and data_file[-9:] == \"train.csv\"):\n",
    "                    print(\"Checking \" + data_file.split(\"/\")[-1][:-9] + \": \", end=\"\")\n",
    "                    test_file = file[:-9] + \"test.csv\"\n",
    "                    val_file = file[:-9] + \"val.csv\"\n",
    "                    new_train = data_file\n",
    "                    new_test = os.path.join(directory,dir_name,test_file)\n",
    "                    new_val = os.path.join(directory,dir_name,val_file)\n",
    "                    old_train = os.path.join(old_directory, dir_name, file)\n",
    "                    old_test = os.path.join(old_directory, dir_name, test_file)\n",
    "                    if (check_equivalent(new_train, new_test, new_val, old_train, old_test)):\n",
    "                        print(\"OKAY\")\n",
    "                    else:\n",
    "                        print(\"BAD!!!!!!!!!!!!!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_difference(new_train_path,new_test_path,new_val_path,old_train_path,old_test_path):\n",
    "    tr1, te1, tr2, te2 = [pd.read_csv(path) for path in [new_train_path, new_test_path, old_train_path, old_test_path]]\n",
    "    new_list = [tr1, te1]\n",
    "    if not new_val_path == \"\" and os.path.exists(new_val_path):\n",
    "        va1 = pd.read_csv(new_val_path)\n",
    "        new_list.append(va1)\n",
    "    new = pd.concat(new_list, ignore_index=True).sort_values(by=['original', 'simple']).reset_index(drop=True)\n",
    "    old = pd.concat([tr2, te2], ignore_index=True).sort_values(by=['original', 'simple']).reset_index(drop=True)\n",
    "    dif = pd.concat([new, old]).drop_duplicates(keep=False)\n",
    "    print(dif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                original  \\\n",
      "1018          \"Es significativo, y es un gran problema\".   \n",
      "1019        \"Es significativo, y es un gran problema\". !   \n",
      "17690  Incluso los hogares cuyos ocupantes están bien...   \n",
      "21783  Los doctores dicen que la deforestación está c...   \n",
      "22517  Los legisladores buscan la forma de regular nu...   \n",
      "22891  Los pobladores de Borneo de Malasia se están e...   \n",
      "25151                                PASCAGOULA, Miss. ?   \n",
      "28947  Sin embargo, de acuerdo a un nuevo informe del...   \n",
      "31838  Varios bomberos tuvieron que permanecer en tie...   \n",
      "1019          \"Es significativo, y es un gran problema\".   \n",
      "17690  Incluso los hogares cuyos ocupantes están bien...   \n",
      "21783  Los doctores dicen que la deforestación está c...   \n",
      "22517  Los legisladores buscan la forma de regular nu...   \n",
      "22891  Los pobladores de Borneo de Malasia se están e...   \n",
      "25151                                  PASCAGOULA, Miss.   \n",
      "28947  Sin embargo, de acuerdo a un nuevo informe del...   \n",
      "31838  Varios bomberos tuvieron que permanecer en tie...   \n",
      "\n",
      "                                                  simple  \n",
      "1018        \"Es significativo, y es un gran problema\". !  \n",
      "1019   Varios bomberos tuvieron que permanecer en tie...  \n",
      "17690  Normalmente, las bacterias no se pueden ver a ...  \n",
      "21783  Las personas se están enfermando de Malaria. ....  \n",
      "22517  El hombre afirma que el empleo inadecuado de l...  \n",
      "22891       Las personas de Malasia se están enfermando.  \n",
      "25151  — Muchos hispanos llegaron a la costa del Golf...  \n",
      "28947  Sin embargo, de acuerdo a un nuevo informe del...  \n",
      "31838  Varios bomberos llegaron al lugar por tierra.L...  \n",
      "1019   Varios bomberos tuvieron que permanecer en tie...  \n",
      "17690  Normalmente, las bacterias no se pueden ver a ...  \n",
      "21783    Los doctores dicen que es por la deforestación.  \n",
      "22517  El hombre afirma que el empleo inadecuado de l...  \n",
      "22891  Las personas de Malasia se están enfermando.La...  \n",
      "25151  — Muchos hispanos llegaron a la costa del Golf...  \n",
      "28947  Sin embargo, de acuerdo a un nuevo informe del...  \n",
      "31838  Varios bomberos llegaron al lugar por tierra.L...  \n"
     ]
    }
   ],
   "source": [
    "find_difference(\"../data/Spanish/Newsela ES_train.csv\",\"../data/Spanish/Newsela ES_test.csv\",\"\",\"../data-old/Spanish/Newsela ES_train.csv\",\"../data-old/Spanish/Newsela ES_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Many will say bad once the references have been grouped.  Run this on ungrouped references for accurate results\n",
      "--------------Japanese--------------\n",
      "Checking Easy Japanese Extended_: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zy/zlsw34jx4zn2cv4tn33_02nh0000gn/T/ipykernel_98187/1684654302.py:3: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  from pandas.util.testing import assert_frame_equal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKAY\n",
      "Checking Easy Japanese Corpus_: BAD!!!!!!!!!!!!!\n",
      "--------------German--------------\n",
      "Checking GEOLino Corpus_: BAD!!!!!!!!!!!!!\n",
      "Checking German News_: BAD!!!!!!!!!!!!!\n",
      "Checking TextComplexityDE Parallel Corpus_: BAD!!!!!!!!!!!!!\n",
      "--------------Slovene--------------\n",
      "Checking Text Simplification Slovene_: BAD!!!!!!!!!!!!!\n",
      "--------------Brazilian Portuguese--------------\n",
      "Checking PorSimples_: BAD!!!!!!!!!!!!!\n",
      "--------------Urdu--------------\n",
      "Checking SimplifyUR_: BAD!!!!!!!!!!!!!\n",
      "--------------Russian--------------\n",
      "Checking RuWikiLarge_: BAD!!!!!!!!!!!!!\n",
      "Checking RuAdapt Ency_: BAD!!!!!!!!!!!!!\n",
      "Checking RSSE Corpus_: OKAY\n",
      "Checking RuAdapt Fairytales_: BAD!!!!!!!!!!!!!\n",
      "Checking RuAdapt Literature_: BAD!!!!!!!!!!!!!\n",
      "--------------Italian--------------\n",
      "Checking Teacher_: BAD!!!!!!!!!!!!!\n",
      "Checking Simpitiki Italian Wikipedia_: BAD!!!!!!!!!!!!!\n",
      "Checking AdminIT_: BAD!!!!!!!!!!!!!\n",
      "Checking PaCCSS-IT Corpus_: BAD!!!!!!!!!!!!!\n",
      "Checking Terence_: BAD!!!!!!!!!!!!!\n",
      "--------------English--------------\n",
      "Checking WikiAuto_: BAD!!!!!!!!!!!!!\n",
      "Checking ASSET_: OKAY\n",
      "Checking Newsela EN_: BAD!!!!!!!!!!!!!\n",
      "--------------Danish--------------\n",
      "Checking DSim Corpus_: BAD!!!!!!!!!!!!!\n",
      "--------------French--------------\n",
      "Checking WikiLargeFR Corpus_: BAD!!!!!!!!!!!!!\n",
      "Checking CLEAR Corpus_: BAD!!!!!!!!!!!!!\n",
      "--------------Spanish--------------\n",
      "Checking Newsela ES_: BAD!!!!!!!!!!!!!\n",
      "Checking Simplext_: BAD!!!!!!!!!!!!!\n",
      "--------------Basque--------------\n",
      "Checking CBST_: BAD!!!!!!!!!!!!!\n"
     ]
    }
   ],
   "source": [
    "check_equivalent_all_data(directory, \"../data-checkpoint/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_to_val(train_df, val_size):\n",
    "  val_df = pd.DataFrame()\n",
    "\n",
    "  while len(val_df) < val_size:\n",
    "    random_line = train_df.sample()\n",
    "    train_counts = train_df['original'].value_counts()\n",
    "    samples = train_df.loc[train_df[\"original\"] == random_line.iloc[0]['original']]\n",
    "    val_df = pd.concat([val_df, samples], ignore_index=True)\n",
    "    train_df = train_df.drop(samples.index)\n",
    "  \n",
    "  return train_df, val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33269\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "train_df, val_df = split_train_to_val(pd.read_csv(\"../data/Japanese/Easy Japanese Extended_train.csv\"), 1000)\n",
    "print(len(train_df))\n",
    "print(len(val_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.to_csv(\"../data/Japanese/Easy Japanese Extended_train2.csv\", index=False)\n",
    "# val_df.to_csv(\"../data/Japanese/Easy Japanese Extended_val2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_swap_multiref(from_counts, from_df, disallow, count):\n",
    "    random_line = from_df.sample()\n",
    "    while (random_line.iloc[0]['original'] not in from_counts) \\\n",
    "      or (from_counts[random_line.iloc[0]['original']] != count) \\\n",
    "      or (random_line.iloc[0]['original'] == disallow):\n",
    "        random_line = from_df.sample()\n",
    "    return from_df.loc[from_df['original'] == random_line.iloc[0]['original']]\n",
    "\n",
    "def swap_row_multiref(df_from, df_to, df_to_counts, sentence):\n",
    "    rows = df_from.loc[df_from['original'] == sentence]\n",
    "    if not rows.empty:\n",
    "        # Move overlap line to df1\n",
    "        df_to = pd.concat([df_to, rows], ignore_index=True)\n",
    "        df_from = df_from.drop(rows.index)\n",
    "\n",
    "        # Move random line to df2\n",
    "        random_line = select_swap_multiref(df_to_counts, df_to, sentence, len(rows))\n",
    "        df_from = pd.concat([df_from, random_line], ignore_index=True)\n",
    "        df_to = df_to.drop(random_line.index)\n",
    "    return df_from, df_to\n",
    "\n",
    "# Align the splits without ever modifying train2 or test2\n",
    "def align_splits_oneside_multiref(train1_path, test1_path, train2_path_lock, test2_path_lock):\n",
    "    tr1, te1, tr2, te2 = [pd.read_csv(path) for path in [train1_path, test1_path, train2_path_lock, test2_path_lock]]\n",
    "    tr1_counts, te1_counts, tr2_counts, te2_counts = [df['original'].value_counts() for df in [tr1, te1, tr2, te2]]\n",
    "    tr1_olen, te1_olen, tr2_olen, te2_olen = [df.shape[0] for df in [tr1,te1,tr2,te2]]\n",
    "\n",
    "    assert verify_no_overlap(tr1, te1) == 0, \"train/test dataframe 1 do not have zero overlap to begin.  Please use fix_overlap.\"\n",
    "    assert verify_no_overlap(tr2, te2) == 0, \"train/test dataframe 2 do not have zero overlap to begin.  Please use fix_overlap.\"\n",
    "\n",
    "    # First guarantee no overlap in train1 and test2\n",
    "    print(\"Align TRAIN1 to TEST2 (reduce overlap)\")\n",
    "    inner = pd.merge(tr1, te2, how ='inner', on =['original', 'original'])\n",
    "    for sentence in tqdm(inner['original']):\n",
    "        if sentence in tr1_counts:\n",
    "            tr1, te1 = swap_row_multiref(tr1, te1, te1_counts, sentence)\n",
    "            tr1_counts, te1_counts = [df['original'].value_counts() for df in [tr1, te1]]\n",
    "\n",
    "    # Second guarantee no overlap in test1 and train2\n",
    "    print(\"Align TEST1 to TRAIN2 (reduce overlap)\")\n",
    "    inner = pd.merge(te1, tr2, how ='inner', on =['original', 'original'])\n",
    "    for sentence in tqdm(inner['original']):\n",
    "        if sentence in te1_counts:\n",
    "            te1, tr1= swap_row_multiref(te1, tr1, tr1_counts, sentence)\n",
    "            tr1_counts, te1_counts = [df['original'].value_counts() for df in [tr1, te1]]\n",
    "    \n",
    "    assert tr1_olen == tr1.shape[0], \"ERROR: Number of rows in train1 changed\"\n",
    "    assert te1_olen == te1.shape[0], \"ERROR: Number of rows in test1 changed\"\n",
    "    assert tr2_olen == tr2.shape[0], \"ERROR: Number of rows in train2 changed\"\n",
    "    assert te2_olen == te2.shape[0], \"ERROR: Number of rows in test2 changed\"\n",
    "\n",
    "    overlap = verify_no_overlap(tr1, te1)\n",
    "    if overlap > 0:\n",
    "        print(\"TRAIN1 to TEST1: BAD (\" + str(overlap) + \" overlap) rerun fix_overlap\")\n",
    "    overlap = verify_no_overlap(tr2, te2)\n",
    "    if overlap > 0:\n",
    "        print(\"TRAIN2 to TEST2: BAD (\" + str(overlap) + \" overlap) rerun fix_overlap\")\n",
    "    overlap = verify_no_overlap(tr1, te2)\n",
    "    if overlap > 0:\n",
    "        print(\"TRAIN1 to TEST2: BAD (\" + str(overlap) + \" overlap) rerun align_splits\")\n",
    "    overlap = verify_no_overlap(tr2, te1)\n",
    "    if overlap > 0:\n",
    "        print(\"TRAIN2 to TEST1: BAD (\" + str(overlap) + \" overlap) rerun align_splits\")\n",
    "    \n",
    "    tr1.to_csv(train1_path, index=False)\n",
    "    te1.to_csv(test1_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Align TRAIN1 to TEST2 (reduce overlap)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Align TEST1 to TRAIN2 (reduce overlap)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "align_splits_oneside_multiref(\"../data/English/ASSET_train.csv\", \"../data/English/ASSET_val.csv\", \"../data/English/WikiAuto_train.csv\", \"../data/English/WikiAuto_val.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Oct 13 2022, 09:48:40) [Clang 14.0.0 (clang-1400.0.29.102)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
